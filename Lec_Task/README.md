**Smart Energy Meter ETL Pipeline**

This project implements a complete ETL (Extractâ€“Transformâ€“Load) pipeline for processing smart-meter electricity consumption data.
The pipeline ensures data quality, standardization, validation, and structured storage to support reliable analytics and reporting.

ğŸ“Œ Project Overview

The system processes raw smart-meter readings uploaded as CSV files.
It performs cleaning, validation, transformation, and structured storage while handling both successful and failed records robustly.

Key objectives of the project:

Ensure data consistency and accuracy

Detect faulty or unreliable meter data

Maintain both raw and clean processed datasets

Prepare data for analytics, dashboards, and forecasting

ğŸ§© ETL Architecture Diagram

Below is the architecture diagram illustrating the full workflow of the ETL system:

![ETL Architecture Diagram](ETL.png)

âš™ï¸ Transformation & Business Rules

During the Transform phase, several business rules are applied:

âœ… Rule 1 â€” Unit Standardization

Convert Watts â†’ Kilowatts

If unknown unit â†’ mark record invalid

âœ… Rule 2 â€” Missing Values Handling

NULL readings are flagged and excluded from peak-usage calculations

âœ… Rule 3 â€” Timestamp Validation

Missing timestamps â†’ invalid

Duplicate timestamps per meter â†’ invalid

âœ… Rule 4 â€” Data Range Validation

Negative values â†’ invalid

Extremely large suspicious values â†’ anomaly flagged

âœ… Rule 5 â€” Faulty Meter Detection

Continuous zero or near-zero readings â†’ potential faulty meter

âœ… Rule 6 â€” Schema Validation

Required fields:

meter_id

timestamp

energy_value

energy_unit

Missing required fields â†’ failure path

ğŸ”„ Single Record Lifecycle

1ï¸âƒ£ Upload to Raw Storage
Data is ingested and stored in raw form for traceability

2ï¸âƒ£ ETL Trigger
New file arrival triggers pipeline execution

3ï¸âƒ£ Cleaning & Validation
Business rules are applied

4ï¸âƒ£ Structured Storage (RDS)
Valid records stored in relational database

5ï¸âƒ£ Archival as Parquet
Optimized for analytics & ML workloads

6ï¸âƒ£ Success / Failure Handling

Success â†’ stored + archived + logged

Failure â†’ routed to failed storage with retries & logging

ğŸ›  Technologies / Concepts Demonstrated

ETL Architecture Design

Data Cleaning & Standardization

Data Quality Validation

Error Handling & Logging

Structured & Analytical Storage Strategies

ğŸ“¬ Contact

Developed by:
Amany Elfiky
ğŸ“§ amanyelfiky2020@gmail.com
